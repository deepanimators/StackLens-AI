# ğŸš€ StackLens AI - Quick Start Guide

Get your advanced AI microservices running in under 5 minutes!

## âš¡ One-Command Setup

```bash
cd ml_microservices
./stacklens_ai.sh setup && ./stacklens_ai.sh start
```

## ğŸ¯ What This Gives You

8 powerful AI microservices ready to analyze error patterns:

| Service                  | Port | Capability                                    |
| ------------------------ | ---- | --------------------------------------------- |
| ğŸ§  **Embeddings**        | 8000 | High-quality text embeddings + clustering     |
| ğŸ” **NER**               | 8001 | Named entity recognition for error data       |
| ğŸ“ **Summarization**     | 8002 | BART-powered error summarization              |
| ğŸ” **Semantic Search**   | 8003 | Vector-based similarity search                |
| âš ï¸ **Anomaly Detection** | 8004 | ML-based anomaly detection                    |
| ğŸ’¾ **Vector Database**   | 8005 | FAISS-powered vector storage                  |
| ğŸ¤– **Deep Learning**     | 8006 | Custom transformers, VAE, GNN, RL             |
| ğŸ“š **Active Learning**   | 8007 | Self-improving AI with uncertainty estimation |

## ğŸ› ï¸ Management Commands

```bash
# Setup environment (one-time)
./stacklens_ai.sh setup

# Start all services
./stacklens_ai.sh start

# Check status
./stacklens_ai.sh status

# Run comprehensive tests
./stacklens_ai.sh test

# View logs
./stacklens_ai.sh logs
./stacklens_ai.sh logs embeddings_service

# Stop all services
./stacklens_ai.sh stop

# Get help
./stacklens_ai.sh help
```

## ğŸ§ª Quick Test

After starting services, test the complete pipeline:

```bash
# Test embeddings
curl -X POST "http://localhost:8000/embed" \
     -H "Content-Type: application/json" \
     -d '{"sentences": ["Database connection timeout", "Memory allocation failed"]}'

# Test semantic search
curl -X POST "http://localhost:8003/semantic-search" \
     -H "Content-Type: application/json" \
     -d '{
       "query": "database error",
       "corpus": [
         "Database connection timeout",
         "Memory allocation failed",
         "Network connection refused"
       ]
     }'

# Or run the full integration test
./stacklens_ai.sh test
```

## ğŸ“Š Expected Results

**Successful startup should show:**

```
âœ… embeddings_service started successfully (PID: 12345)
âœ… ner_service started successfully (PID: 12346)
âœ… summarization_service started successfully (PID: 12347)
âœ… semantic_search_service started successfully (PID: 12348)
âœ… anomaly_service started successfully (PID: 12349)
âœ… vector_db_service started successfully (PID: 12350)
âœ… deep_learning_service started successfully (PID: 12351)
âœ… active_learning_service started successfully (PID: 12352)
```

**Integration tests should show 80%+ pass rate:**

```
ğŸ¯ INTEGRATION TEST SUMMARY
âœ… Passed: 8/10 (80.0%)
ğŸ‰ INTEGRATION TEST SUITE: PASSED
```

## ğŸ³ Docker Alternative

If you prefer Docker:

```bash
# Build and start with Docker Compose
docker-compose up --build -d

# Check status
docker-compose ps

# View logs
docker-compose logs -f

# Stop
docker-compose down
```

## ğŸ”§ Troubleshooting

**Port conflicts:**

```bash
# Check what's using a port
lsof -i:8000

# Kill process on port
lsof -ti:8000 | xargs kill -9
```

**Memory issues:**

```bash
# Check memory usage
free -h

# Monitor service memory
./stacklens_ai.sh logs embeddings_service
```

**Service won't start:**

```bash
# Check detailed logs
./stacklens_ai.sh logs [service_name]

# Check Python environment
source stacklens_ai_venv/bin/activate
python3 -c "import torch; print('PyTorch version:', torch.__version__)"
```

## ğŸ‰ Next Steps

1. **Integrate with your StackLens application**
2. **Feed real error data through the pipeline**
3. **Monitor active learning improvements**
4. **Scale services based on usage**

## ğŸ“š Full Documentation

See `README.md` for complete API documentation and advanced configuration options.

---

**ğŸš€ You now have a production-ready AI platform for advanced error analysis!**
