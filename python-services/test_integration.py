#!/usr/bin/env python3
"""
Test script to verify deep learning integration
Run this to check if all components are working correctly
"""

import requests
import json
import time
import sys
import os

def test_service(service_name, port, endpoint="/health"):
    """Test if a service is running"""
    try:
        response = requests.get(f"http://localhost:{port}{endpoint}", timeout=5)
        if response.status_code == 200:
            print(f"‚úÖ {service_name} (port {port}) - Running")
            return True
        else:
            print(f"‚ùå {service_name} (port {port}) - HTTP {response.status_code}")
            return False
    except requests.exceptions.ConnectionError:
        print(f"‚ùå {service_name} (port {port}) - Not running")
        return False
    except Exception as e:
        print(f"‚ùå {service_name} (port {port}) - Error: {e}")
        return False

def test_deep_learning_api():
    """Test the deep learning API specifically"""
    print("\nüß† Testing Deep Learning API...")
    
    # Test health check
    if not test_service("Deep Learning API", 8006, "/"):
        return False
    
    # Test status endpoint
    try:
        response = requests.get("http://localhost:8006/status")
        if response.status_code == 200:
            status = response.json()
            print(f"üìä Models loaded: {len(status.get('models', {}))}")
            print(f"üéØ GPU available: {status.get('gpu_available', False)}")
            print(f"üßÆ PyTorch available: {status.get('pytorch_available', False)}")
        else:
            print(f"‚ö†Ô∏è Status endpoint returned {response.status_code}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not get status: {e}")
    
    # Test prediction endpoint with sample data
    try:
        test_data = {
            "error_context": {
                "message": "NullPointerException in UserService",
                "timestamp": "2024-01-15T10:30:00Z",
                "system_state": {"cpu": 85, "memory": 78, "load": "high"},
                "recent_errors": ["ConnectionTimeout", "DatabaseLock"]
            }
        }
        
        response = requests.post(
            "http://localhost:8006/predict",
            json=test_data,
            timeout=30
        )
        
        if response.status_code == 200:
            result = response.json()
            print(f"üéØ Prediction successful!")
            print(f"   Severity: {result.get('predicted_severity', 'N/A')}")
            print(f"   Category: {result.get('predicted_category', 'N/A')}")
            print(f"   Confidence: {result.get('confidence', 'N/A')}")
            return True
        else:
            print(f"‚ùå Prediction failed: HTTP {response.status_code}")
            print(f"   Response: {response.text}")
            return False
            
    except Exception as e:
        print(f"‚ùå Prediction error: {e}")
        return False

def test_all_microservices():
    """Test all microservices"""
    print("üîç Testing All Microservices...\n")
    
    services = [
        ("Embeddings Service", 8001),
        ("NER Service", 8002),
        ("Summarization Service", 8003),
        ("Semantic Search", 8004),
        ("Anomaly Detection", 8005),
        ("Deep Learning", 8006),
        ("Vector Database", 8007)
    ]
    
    running_services = 0
    for service_name, port in services:
        if test_service(service_name, port):
            running_services += 1
    
    print(f"\nüìà Services running: {running_services}/{len(services)}")
    return running_services == len(services)

def check_environment():
    """Check if environment is properly set up"""
    print("üîß Checking Environment...\n")
    
    # Check Python version
    python_version = sys.version_info
    print(f"üêç Python version: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # Check if we're in the right directory
    if os.path.exists("deep_learning_models.py"):
        print("‚úÖ Deep learning files found")
    else:
        print("‚ùå Deep learning files not found - make sure you're in the ml_microservices directory")
        return False
    
    # Check for Docker
    try:
        import subprocess
        result = subprocess.run(["docker", "--version"], capture_output=True, text=True)
        if result.returncode == 0:
            print("‚úÖ Docker available")
        else:
            print("‚ö†Ô∏è Docker not available")
    except:
        print("‚ö†Ô∏è Docker not available")
    
    # Check for key Python packages
    packages = ["torch", "transformers", "fastapi", "uvicorn"]
    for package in packages:
        try:
            __import__(package)
            print(f"‚úÖ {package} installed")
        except ImportError:
            print(f"‚ùå {package} not installed")
    
    return True

def run_integration_test():
    """Run a comprehensive integration test"""
    print("üöÄ Running Integration Test for Deep Learning StackLens AI\n")
    print("=" * 60)
    
    # Step 1: Check environment
    if not check_environment():
        print("\n‚ùå Environment check failed")
        return False
    
    print("\n" + "=" * 60)
    
    # Step 2: Test microservices
    all_services_running = test_all_microservices()
    
    print("\n" + "=" * 60)
    
    # Step 3: Deep learning specific tests
    if not test_deep_learning_api():
        print("\n‚ö†Ô∏è Deep learning API tests failed")
        if not all_services_running:
            print("üí° Tip: Make sure to run './launch_all_enhanced.sh' first")
    
    print("\n" + "=" * 60)
    print("üéØ Integration Test Complete!")
    
    if all_services_running:
        print("‚úÖ All systems operational - Your StackLens AI is ready!")
        print("\nüîó Access your services at:")
        print("   ‚Ä¢ Deep Learning API: http://localhost:8006")
        print("   ‚Ä¢ Embeddings: http://localhost:8001")
        print("   ‚Ä¢ NER: http://localhost:8002")
        print("   ‚Ä¢ Summarization: http://localhost:8003")
        print("   ‚Ä¢ Semantic Search: http://localhost:8004")
        print("   ‚Ä¢ Anomaly Detection: http://localhost:8005")
        print("   ‚Ä¢ Vector Database: http://localhost:8007")
    else:
        print("‚ö†Ô∏è Some services are not running")
        print("\nüõ†Ô∏è To start all services:")
        print("   cd ml_microservices")
        print("   ./launch_all_enhanced.sh")
        print("   # Or use Docker Compose:")
        print("   docker-compose up --build")

if __name__ == "__main__":
    run_integration_test()
