StackLens AI: Project Overview
1. Project Purpose and Vision
StackLens AI is a robust, AI-powered log analysis SaaS platform designed to automate the detection, classification, and resolution of errors in log files. It aims to provide organizations and developers with a self-learning, intelligent system that not only parses and analyzes logs from various sources but also offers actionable insights, AI-driven suggestions, and auto-resolution capabilities. The platform is built to handle large-scale log ingestion, support multiple log formats, and provide a modern, user-friendly web interface for monitoring, filtering, and exporting error data.

2. High-Level Architecture
A. Backend (Flask/Python)
Flask Application: The core web server, API provider, and orchestrator for all backend logic.
Database (SQLAlchemy): Stores analysis metadata, error details, user uploads, and model information.
Log Parsing & Error Extraction: Modular parsers for different log formats, with a central error extraction engine.
Machine Learning Engine: Provides error classification, severity prediction, and AI suggestions using both local models and Gemini fallback.
Export Utilities: Allows exporting error data in CSV, XLSX, and JSON formats, with deduplication and severity prioritization.
Background Processing: Uses threading to handle long-running log analysis jobs asynchronously.
B. Frontend (Jinja2/Bootstrap/JS)
Modern UI: Responsive, theme-adaptive interface using Bootstrap, with custom JS for upload, progress, and filtering.
Dashboard: Central hub for monitoring analyses, statistics, and recent activity.
All Errors Page: Consolidated, filterable, and sortable error list across all files.
Reports & History: Detailed per-file and historical analysis views.
Export & Download: UI elements for exporting error data in various formats.
Modals & AJAX: For progress, error details, and AI suggestions.
3. Key Modules and Their Roles
A. Log Parsing and Error Extraction
parsers: Contains format-specific parsers (CSV, JSON, XML, YAML, etc.) and a central error_parser.py.
ErrorParser: Uses regex patterns and severity mappings to extract errors from log lines. Supports deduplication and debug logging.
Pattern Matching: Patterns for general errors, timeouts, memory issues, network errors, permission errors, warnings, and custom business errors.
Severity Mapping: Maps keywords to severity levels (critical, high, medium, low).
B. Machine Learning and AI
ml_engine: Contains the ML pipeline, including error analyzers, predictors, trainers, and suggestors.
EnhancedErrorAnalyzer: Analyzes error text for category, confidence, sentiment, entities, key phrases, severity, and suggested actions.
LogPredictor: Predicts error types and provides suggestions using trained models.
ErrorSuggestor: Pattern-based and ML-based suggestion engine, with Gemini fallback for low-confidence cases.
Model Training: Supports retraining from database, with metrics reporting (accuracy, precision, recall, F1, CV).
C. Data Storage and Models
models.py: Defines the LogAnalysis SQLAlchemy model, which stores:
File metadata (name, type, size, timestamps)
Status and error counts (total, critical, high, medium, low)
Extracted errors, suggestions, predictions, and anomalies (as JSON fields)
Database: SQLite by default, with support for other backends.
D. Backend API and Routes
routes.py: Main Flask routes and API endpoints.
Upload & Analysis: Handles file uploads, starts background analysis, and updates DB.
Status & Progress: API endpoints for polling analysis status.
Dashboard & All Errors: Renders main UI pages, passing filtered and deduplicated error data.
Export: /export_errors endpoint supports CSV, XLSX, JSON, with deduplication and highest-severity logic.
AI Suggestion: Endpoint for fetching AI suggestions for specific errors.
Error Handling: Custom error pages and handlers for 404, 500, and file size limits.
E. Export Utilities
export.py: Provides functions to export error data in various formats.
Deduplication: Ensures only one entry per (file, line, message), always keeping the highest severity.
Format Support: CSV (via csv), XLSX (via pandas), JSON (via json).
Flask Response: Returns downloadable files with correct MIME types and headers.
4. Frontend Features and User Experience
A. File Upload and Progress
Drag-and-drop and multi-file upload support.
Real-time progress modal with AJAX polling for analysis status.
Asynchronous background processing, with UI updates on completion.
B. Dashboard
Displays summary statistics (total files, completed analyses, errors found, critical issues).
Recent analysis results table with per-file actions (view, export).
Navigation tabs for Overview, History, Reports, and AI Analysis.
C. All Errors Page
Consolidated error list across all files.
Global filtering (severity, search, file name), sorting, and pagination.
Deduplication and highest-severity logic applied for consistency with export.
Export dropdown for CSV, XLSX, JSON.
D. Reports and History
Per-file and historical analysis views.
Error breakdowns, severity counts, and AI suggestions.
Download/export options for each file.
E. AI Suggestions and Modals
On-demand AI suggestions for each error, with modal popups.
Fallback to Gemini for low-confidence cases.
Pretty timestamp formatting and severity badges.
5. Technical Highlights and Best Practices
Threaded Background Analysis: Ensures UI remains responsive during long-running log analysis.
Deduplication and Severity Prioritization: Both export and UI use the same logic to avoid confusion and ensure data integrity.
Modular Design: Parsers, ML engine, and export utilities are decoupled for maintainability and extensibility.
Robust Error Handling: Graceful handling of upload errors, analysis failures, and large files.
Debug Logging: Error extraction includes debug logs for troubleshooting pattern matches and extraction logic.
Extensible Patterns: Easy to add new error patterns or log formats as business needs evolve.
Security: Uses secure_filename for uploads, and restricts file types and sizes.
6. Deployment and Extensibility
Requirements: Python 3.x, Flask, Flask-SQLAlchemy, pandas, openpyxl, and other standard libraries.
Deployment: Can be run locally or deployed to any WSGI-compatible server.
Extensibility:
Add new log parsers by extending parsers.
Add new ML models or retrain via the /api/train_model endpoint.
Integrate with external AI services (e.g., Gemini) for advanced suggestions.
Customize UI via Jinja2 templates and static assets.
7. Recent Improvements and Fixes
Unified deduplication and severity logic for both UI and export.
Added debug logging to error extraction for easier troubleshooting.
Improved export and UI consistency for old and new data.
Added export dropdowns to dashboard, reports, and per-file actions.
Fixed issues with progress modal, polling, and upload flow.
Enhanced filtering, sorting, and pagination on the All Errors page.
8. Potential Next Steps and Enhancements
User Authentication: Add user accounts and per-user data isolation.
Role-Based Access: Different permissions for admins, analysts, and viewers.
Scheduled/Automated Log Ingestion: Support for cron jobs or API-based log uploads.
Advanced AI/ML: Integrate more sophisticated models, anomaly detection, or root cause analysis.
Notification System: Email or webhook alerts for critical errors.
Audit Trail: Track changes, deletions, and user actions for compliance.
API for External Integration: Allow other systems to push logs or fetch analysis results programmatically.
9. Summary
StackLens AI is a comprehensive, production-grade log analysis platform that combines robust parsing, AI-driven insights, and a modern, user-friendly interface. Its architecture is modular and extensible, making it suitable for both small teams and enterprise deployments. The system is designed for reliability, accuracy, and ease of use, with a focus on actionable intelligence and automation.

---

# StackLens AI: Detailed Project Overview

## 1. Project Purpose and Vision
StackLens AI is a robust, AI-powered log analysis SaaS platform designed to automate the detection, classification, and resolution of errors in log files. It aims to provide organizations and developers with a self-learning, intelligent system that not only parses and analyzes logs from various sources but also offers actionable insights, AI-driven suggestions, and auto-resolution capabilities. The platform is built to handle large-scale log ingestion, support multiple log formats, and provide a modern, user-friendly web interface for monitoring, filtering, and exporting error data.

## 2. High-Level Architecture
### A. Backend (Flask/Python)
- **Flask Application**: The core web server, API provider, and orchestrator for all backend logic.
- **Database (SQLAlchemy)**: Stores analysis metadata, error details, user uploads, and model information.
- **Log Parsing & Error Extraction**: Modular parsers for different log formats, with a central error extraction engine.
- **Machine Learning Engine**: Provides error classification, severity prediction, and AI suggestions using both local models and Gemini fallback.
- **Export Utilities**: Allows exporting error data in CSV, XLSX, and JSON formats, with deduplication and severity prioritization.
- **Background Processing**: Uses threading to handle long-running log analysis jobs asynchronously.

### B. Frontend (Jinja2/Bootstrap/JS)
- **Modern UI**: Responsive, theme-adaptive interface using Bootstrap, with custom JS for upload, progress, and filtering.
- **Dashboard**: Central hub for monitoring analyses, statistics, and recent activity.
- **All Errors Page**: Consolidated, filterable, and sortable error list across all files.
- **Reports & History**: Detailed per-file and historical analysis views.
- **Export & Download**: UI elements for exporting error data in various formats.
- **Modals & AJAX**: For progress, error details, and AI suggestions.

## 3. Key Modules and Their Roles
### A. Log Parsing and Error Extraction
- **parsers/**: Contains format-specific parsers (CSV, JSON, XML, YAML, etc.) and a central `error_parser.py`.
  - **ErrorParser**: Uses regex patterns and severity mappings to extract errors from log lines. Supports deduplication and debug logging.
  - **Pattern Matching**: Patterns for general errors, timeouts, memory issues, network errors, permission errors, warnings, and custom business errors.
  - **Severity Mapping**: Maps keywords to severity levels (critical, high, medium, low).

### B. Machine Learning and AI
- **ml_engine/**: Contains the ML pipeline, including error analyzers, predictors, trainers, and suggestors.
  - **EnhancedErrorAnalyzer**: Analyzes error text for category, confidence, sentiment, entities, key phrases, severity, and suggested actions.
  - **LogPredictor**: Predicts error types and provides suggestions using trained models.
  - **ErrorSuggestor**: Pattern-based and ML-based suggestion engine, with Gemini fallback for low-confidence cases.
  - **Model Training**: Supports retraining from database, with metrics reporting (accuracy, precision, recall, F1, CV).

### C. Data Storage and Models
- **models.py**: Defines the `LogAnalysis` SQLAlchemy model, which stores:
  - File metadata (name, type, size, timestamps)
  - Status and error counts (total, critical, high, medium, low)
  - Extracted errors, suggestions, predictions, and anomalies (as JSON fields)
- **Database**: SQLite by default, with support for other backends.

### D. Backend API and Routes
- **routes.py**: Main Flask routes and API endpoints.
  - **Upload & Analysis**: Handles file uploads, starts background analysis, and updates DB.
  - **Status & Progress**: API endpoints for polling analysis status.
  - **Dashboard & All Errors**: Renders main UI pages, passing filtered and deduplicated error data.
  - **Export**: `/export_errors` endpoint supports CSV, XLSX, JSON, with deduplication and highest-severity logic.
  - **AI Suggestion**: Endpoint for fetching AI suggestions for specific errors.
  - **Error Handling**: Custom error pages and handlers for 404, 500, and file size limits.

### E. Export Utilities
- **utils/export.py**: Provides functions to export error data in various formats.
  - **Deduplication**: Ensures only one entry per (file, line, message), always keeping the highest severity.
  - **Format Support**: CSV (via `csv`), XLSX (via `pandas`), JSON (via `json`).
  - **Flask Response**: Returns downloadable files with correct MIME types and headers.

## 4. Frontend Features and User Experience
### A. File Upload and Progress
- Drag-and-drop and multi-file upload support.
- Real-time progress modal with AJAX polling for analysis status.
- Asynchronous background processing, with UI updates on completion.

### B. Dashboard
- Displays summary statistics (total files, completed analyses, errors found, critical issues).
- Recent analysis results table with per-file actions (view, export).
- Navigation tabs for Overview, History, Reports, and AI Analysis.

### C. All Errors Page
- Consolidated error list across all files.
- Global filtering (severity, search, file name), sorting, and pagination.
- Deduplication and highest-severity logic applied for consistency with export.
- Export dropdown for CSV, XLSX, JSON.

### D. Reports and History
- Per-file and historical analysis views.
- Error breakdowns, severity counts, and AI suggestions.
- Download/export options for each file.

### E. AI Suggestions and Modals
- On-demand AI suggestions for each error, with modal popups.
- Fallback to Gemini for low-confidence cases.
- Pretty timestamp formatting and severity badges.

## 5. Technical Highlights and Best Practices
- **Threaded Background Analysis**: Ensures UI remains responsive during long-running log analysis.
- **Deduplication and Severity Prioritization**: Both export and UI use the same logic to avoid confusion and ensure data integrity.
- **Modular Design**: Parsers, ML engine, and export utilities are decoupled for maintainability and extensibility.
- **Robust Error Handling**: Graceful handling of upload errors, analysis failures, and large files.
- **Debug Logging**: Error extraction includes debug logs for troubleshooting pattern matches and extraction logic.
- **Extensible Patterns**: Easy to add new error patterns or log formats as business needs evolve.
- **Security**: Uses `secure_filename` for uploads, and restricts file types and sizes.

## 6. Deployment and Extensibility
- **Requirements**: Python 3.x, Flask, Flask-SQLAlchemy, pandas, openpyxl, and other standard libraries.
- **Deployment**: Can be run locally or deployed to any WSGI-compatible server.
- **Extensibility**:
  - Add new log parsers by extending `parsers/`.
  - Add new ML models or retrain via the `/api/train_model` endpoint.
  - Integrate with external AI services (e.g., Gemini) for advanced suggestions.
  - Customize UI via Jinja2 templates and static assets.

## 7. Recent Improvements and Fixes
- Unified deduplication and severity logic for both UI and export.
- Added debug logging to error extraction for easier troubleshooting.
- Improved export and UI consistency for old and new data.
- Added export dropdowns to dashboard, reports, and per-file actions.
- Fixed issues with progress modal, polling, and upload flow.
- Enhanced filtering, sorting, and pagination on the All Errors page.

## 8. Potential Next Steps and Enhancements
- **User Authentication**: Add user accounts and per-user data isolation.
- **Role-Based Access**: Different permissions for admins, analysts, and viewers.
- **Scheduled/Automated Log Ingestion**: Support for cron jobs or API-based log uploads.
- **Advanced AI/ML**: Integrate more sophisticated models, anomaly detection, or root cause analysis.
- **Notification System**: Email or webhook alerts for critical errors.
- **Audit Trail**: Track changes, deletions, and user actions for compliance.
- **API for External Integration**: Allow other systems to push logs or fetch analysis results programmatically.

## 9. Summary
StackLens AI is a comprehensive, production-grade log analysis platform that combines robust parsing, AI-driven insights, and a modern, user-friendly interface. Its architecture is modular and extensible, making it suitable for both small teams and enterprise deployments. The system is designed for reliability, accuracy, and ease of use, with a focus on actionable intelligence and automation.

---

# StackLens AI: Code-Level Walkthrough & Visual Architecture

## 1. Visual Architecture Diagram (ASCII)

```
+-------------------+         +-------------------+         +-------------------+
|                   |         |                   |         |                   |
|   User Browser    +-------->+   Flask Backend   +-------->+    Database       |
| (JS, Bootstrap,   |  HTTP   |  (routes.py, API, |  ORM    | (SQLAlchemy,      |
|  Jinja2 Templates)|         |   ML Engine)      |         |  LogAnalysis)     |
|                   |         |                   |         |                   |
+-------------------+         +-------------------+         +-------------------+
         |                             |                             |
         |                             |                             |
         |                             v                             |
         |                  +-------------------+                   |
         |                  |                   |                   |
         |                  |  Log Parsers      |                   |
         |                  | (parsers/*.py)    |                   |
         |                  +-------------------+                   |
         |                             |                             |
         |                             v                             |
         |                  +-------------------+                   |
         |                  |                   |                   |
         |                  |  ML Engine        |                   |
         |                  | (ml_engine/*)     |                   |
         |                  +-------------------+                   |
         |                             |                             |
         |                             v                             |
         |                  +-------------------+                   |
         |                  |                   |                   |
         |                  | Export Utilities  |                   |
         |                  | (utils/export.py) |                   |
         |                  +-------------------+                   |
```
Legend:
Frontend: User interacts via web UI (upload, dashboard, error list, export, modals).
Flask App/API: Orchestrates uploads, analysis, status, export, and AI suggestions.
Log Parsing/Extraction: Modular parsers extract errors, deduplicate, and assign severity.
ML Engine: Classifies errors, predicts severity, and generates suggestions.
Database: Stores all analysis metadata, error details, and model info.
Export Utilities: Deduplicate and export error data in user-selected formats.

## 2. Code-Level Walkthrough

### A. Entry Point & App Setup
- **app.py / app_factory.py**: Creates the Flask app, configures extensions, registers blueprints/routes.
- **models.py**: Defines the `LogAnalysis` SQLAlchemy model for storing analysis metadata and error details.

### B. File Upload & Analysis
- **/upload** (route in `routes.py`):
  - Receives file(s) from the user via the web UI.
  - Saves files to the `uploads/` directory.
  - Creates a `LogAnalysis` DB entry for each file.
  - Starts a background thread to analyze each file.

- **Background Analysis Thread**:
  - Calls `process_log_file()` (in `routes.py`), which:
    - Detects file type and selects the appropriate parser from `parsers/`.
    - Reads file content and parses it for lines and structure.
    - Uses `ErrorParser.extract_errors()` to extract error objects from the content.
    - Passes errors to the ML engine (`ml_engine/`) for classification, prediction, and suggestions.
    - Updates the `LogAnalysis` DB entry with errors, suggestions, predictions, and status.

### C. Error Extraction & Parsing
- **parsers/error_parser.py**:
  - Contains `ErrorParser` class with regex-based error patterns and severity mapping.
  - `extract_errors()` splits content into lines, applies patterns, and deduplicates errors.
  - Debug logging shows which lines matched which patterns.

### D. Machine Learning & Suggestions
- **ml_engine/**:
  - `EnhancedErrorAnalyzer`, `LogPredictor`, `ErrorSuggestor` provide ML-based error classification, severity prediction, and suggestions.
  - Can use local models or fallback to Gemini for low-confidence cases.
  - Model training and metrics via `/api/train_model`.

### E. API & UI Integration
- **routes.py**:
  - `/api/analysis/<id>`: Returns detailed analysis data for a file.
  - `/api/analysis/<id>/status`: Returns status/progress for polling.
  - `/all_errors`: Renders the All Errors page, consolidating and deduplicating errors, always showing the highest severity.
  - `/export_errors`: Exports deduplicated error data in CSV, XLSX, or JSON.

- **templates/**:
  - `dashboard.html`, `all_errors.html`, etc.: Jinja2 templates render tables, modals, and export buttons.
  - JS (in `static/js/`) handles upload, progress, AJAX polling, and modals.

### F. Export Utilities
- **utils/export.py**:
  - `deduplicate_errors()`: Ensures only one error per (file, line, message), always keeping the highest severity.
  - `export_errors_csv/json/xlsx()`: Output error data in the requested format.

### G. User Experience
- **Progress Modal**: Shows upload/analysis progress, updates via AJAX polling.
- **Dashboard**: Shows summary stats, recent analyses, and per-file actions.
- **All Errors Page**: Global filtering, sorting, pagination, and export.
- **Reports/History**: Per-file and historical error breakdowns.
- **AI Suggestions**: On-demand, with fallback to Gemini if needed.

---

This diagram and walkthrough should help you (or new developers) quickly understand the flow and structure of StackLens AI. If you want a more detailed diagram (e.g., with sequence flows or per-module call graphs), let me know!

Code-Level Walkthrough
1. Entry Points & App Factory
app.py / app_factory.py: Initializes the Flask app, configures extensions (SQLAlchemy, etc.), registers blueprints, and sets up error handlers.
run.py / main.py: Script entry points to start the Flask server.
2. Configuration & Extensions
config.py: Centralizes environment variables, DB URIs, and app settings.
extensions.py: Initializes Flask extensions (e.g., SQLAlchemy, CORS).
3. Data Models
models.py: Defines the LogAnalysis SQLAlchemy model, which stores:
File metadata (name, type, size, timestamps)
Status and error counts
Extracted errors, suggestions, predictions (JSON fields)
4. Log Parsing & Error Extraction
parsers: Contains format-specific parsers (CSV, JSON, XML, etc.).
error_parser.py: Central engine for extracting errors using regex patterns and severity mappings.
log_parser.py: Handles generic log formats.
log_patterns.py: Houses regex patterns for error types.
Debug logging is included for troubleshooting extraction logic.
5. Machine Learning & AI
ml_engine: ML pipeline for error analysis.
core.py: Orchestrates ML tasks.
error_analyzer.py: Classifies errors, predicts severity, extracts features.
predictor.py: Loads and applies trained models.
suggestor.py: Provides AI suggestions (local model or Gemini fallback).
model_trainer.py: Handles model retraining and metrics.
6. Backend API & Routes
routes.py: Main Flask routes:
/upload: Handles file uploads, triggers background analysis.
/status: Returns analysis progress.
/dashboard, /all_errors: Renders main UI pages, passing deduplicated error data.
/export_errors: Exports errors (CSV/XLSX/JSON) with deduplication/highest-severity logic.
/ai_suggestion: Returns AI suggestions for errors.
Background analysis: Uses threading to keep UI responsive.
7. Export Utilities
export.py: Functions for exporting error data.
Deduplicates errors by (file, line, message), keeping the highest severity.
Supports CSV (via csv), XLSX (via pandas), JSON (via json).
8. Frontend (Jinja2/Bootstrap/JS)
Templates: base.html, dashboard.html, all_errors.html, etc.
Use Bootstrap for layout, modals for progress and AI suggestions.
Tables for error lists, with filtering, sorting, and pagination.
Static JS: main.js (upload, AJAX, modals, progress), theme.js (theme switching).
Static CSS: themes.css for theme-adaptive styles.
9. Batch & Debug Scripts
debug_error_extraction.py: For batch error extraction and debugging.


